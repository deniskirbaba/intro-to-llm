{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwdq-muGjYov"
      },
      "outputs": [],
      "source": [
        "#!pip install keybert spacy sklearn sentence_transformers langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FHEULa0jYo1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqFts6wHjYo2"
      },
      "source": [
        "# Продвинутые техники RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1XRmOb0jYo5"
      },
      "source": [
        "## 1. Сжатие промптов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBigoACejYo7"
      },
      "source": [
        "### 1.1. Зачем нужно сжатие промптов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa39pOZEjYo8"
      },
      "source": [
        "**Проблема ресурсоемкости**: Каждый запрос в LLM (Language Model) ограничен по количеству символов, а большие промпты требуют значительных вычислительных мощностей. Сокращение промпта — это способ повысить производительность и сделать процесс более экономичным.\n",
        "\n",
        "**Улучшение скорости обработки**: Сжатие промптов ускоряет время обработки запроса и может повысить общую точность ответа, так как модель обрабатывает только ключевую информацию.\n",
        "\n",
        "**Фокус на релевантной информации**: В больших промптах часто много избыточной информации, и задача сжатия — выделить только необходимые элементы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZbnzmCkjYo_"
      },
      "source": [
        "### 1.2. Методы сжатия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-MV2j6UjYpB"
      },
      "source": [
        "##### Метод 1: Сжатие на основе ключевых слов (Keyword Extraction)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0GA2QetjYpC"
      },
      "source": [
        "Ключевые слова помогают выделить основные аспекты запроса, которые будут важны для генерации ответа. Один из популярных инструментов для этого — библиотека KeyBERT, которая использует BERT для нахождения ключевых слов в тексте.\n",
        "\n",
        "\n",
        "**Преимущества**: Простота и быстрая реализация. Полезно в ситуациях, когда запрос достаточно длинный и содержит много уточняющих деталей.  \n",
        "\n",
        "**Недостатки**: Иногда ключевые слова могут не учитывать контекст, и часть важной информации может быть утрачена."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To9KGjA5jYpD",
        "outputId": "d22f37eb-e8c4-4127-90f9-f53db6a6ec5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressed Query (Keywords): rag techniques query responses advanced rag advantages using rag\n"
          ]
        }
      ],
      "source": [
        "from keybert import KeyBERT\n",
        "\n",
        "# Инициализация модели KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "def compress_prompt_keywords(query):\n",
        "    # Извлечение топ-5 ключевых слов\n",
        "    keywords = kw_model.extract_keywords(query, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=5)\n",
        "    return \" \".join([word[0] for word in keywords])\n",
        "\n",
        "# Пример использования\n",
        "query = \"What are the main advantages of using advanced RAG techniques for improving query responses?\"\n",
        "compressed_query = compress_prompt_keywords(query)\n",
        "print(\"Compressed Query (Keywords):\", compressed_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k5EcZHZjYpF"
      },
      "source": [
        "##### Метод 2: Сжатие на основе извлечения сущностей (Named Entity Recognition, NER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1wDKUyYjYpF"
      },
      "source": [
        "С помощью NER можно выделить важные сущности, такие как имена людей, даты, локации, которые несут смысловую нагрузку в запросе. Этот метод эффективен для извлечения основных фактов из длинных запросов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzPwy6q7jYpG"
      },
      "source": [
        "**Преимущества**: Высокая точность при работе с фактологической информацией.  \n",
        "\n",
        "**Недостатки**: При запросах, содержащих описания или абстрактные темы, данный метод может терять важные детали."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrCLneNbjYpG",
        "outputId": "3e7a2617-d8e6-4846-c16d-03ec941fc61c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressed Query (Entities): Corrective RAG OpenAI 2024\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "#!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Загрузка предобученной модели spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def compress_prompt_entities(query):\n",
        "    doc = nlp(query)\n",
        "    # Извлечение только нужных типов сущностей\n",
        "    entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"DATE\", \"TIME\"]]\n",
        "    return \" \".join(entities)\n",
        "\n",
        "# Пример использования\n",
        "query = \"Describe the impact of Corrective RAG introduced by OpenAI in 2024 on information retrieval.\"\n",
        "compressed_query = compress_prompt_entities(query)\n",
        "print(\"Compressed Query (Entities):\", compressed_query)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua5CMiWyjYpG"
      },
      "source": [
        "##### Метод 3: Сжатие с использованием TF-IDF (Term Frequency - Inverse Document Frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5EE34BTjYpH"
      },
      "source": [
        "TF-IDF помогает выбрать термины, которые наиболее важны для конкретного запроса, на основе их частоты. Этот метод учитывает не только популярные слова, но и те, которые важны именно для данного запроса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7NWlwGRjYpH"
      },
      "source": [
        "**Преимущества**: Подходит для запросов с большим объемом текста, так как учитывает уникальность терминов.  \n",
        "\n",
        "**Недостатки**: Требует дополнительных данных (контекста) для лучшего определения важных терминов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo64AHCCjYpH",
        "outputId": "c799676e-0f90-41ad-a083-ac0fc0009c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressed Query (TF-IDF): what introduced the advancements are\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def compress_prompt_tfidf(query, documents):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform([query] + documents)\n",
        "    feature_array = vectorizer.get_feature_names_out()\n",
        "    tfidf_sorting = tfidf_matrix[0].toarray().flatten().argsort()[::-1]\n",
        "    # Извлечение топ-5 терминов\n",
        "    top_n = tfidf_sorting[:5]\n",
        "    return \" \".join([feature_array[i] for i in top_n])\n",
        "\n",
        "# Пример использования\n",
        "documents = [\"RAG is a technique for using external data in generation.\", \"Corrective RAG improves response accuracy.\"]\n",
        "query = \"What are the main advancements in RAG models introduced by OpenAI?\"\n",
        "compressed_query = compress_prompt_tfidf(query, documents)\n",
        "print(\"Compressed Query (TF-IDF):\", compressed_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84avzdSXjYpH"
      },
      "source": [
        "##### Метод 4: Семантическое сжатие с помощью Sentence-BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0htz7AgujYpI"
      },
      "source": [
        "Модель Sentence-BERT создает компактные векторные представления для запросов и текстов, позволяя сохранять семантическое сходство. Это полезно для сжатия запроса в один или два важных предложения, сохраняя его значение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En_90IiZjYpI"
      },
      "source": [
        "**Преимущества**: Сохраняет высокий уровень семантического сходства между исходным запросом и сжатым текстом.  \n",
        "\n",
        "**Недостатки**: Зависит от качества обучающих данных и параметров модели, требует дополнительных вычислительных ресурсов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn0uMNYIjYpJ",
        "outputId": "4145be29-aa42-4bb0-d205-711f1aeff803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores for each document:\n",
            "Document 1: 0.4097\n",
            "Document 2: 0.6019\n",
            "Document 3: 0.5204\n",
            "Document 4: 0.4829\n",
            "\n",
            "Compressed Query (BERT): Corrective RAG models apply specific techniques to refine and correct generated responses based on context.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Инициализация модели Sentence-BERT\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def compress_prompt_bert(query, documents):\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    doc_embeddings = model.encode(documents, convert_to_tensor=True)\n",
        "\n",
        "    # Нахождение и вывод значений схожести\n",
        "    scores = util.pytorch_cos_sim(query_embedding, doc_embeddings).squeeze()\n",
        "    print(\"Scores for each document:\")\n",
        "    for i, score in enumerate(scores):\n",
        "        print(f\"Document {i + 1}: {score.item():.4f}\")\n",
        "\n",
        "    # Нахождение индекса наиболее релевантного документа\n",
        "    top_idx = scores.argmax().item()\n",
        "\n",
        "    # Проверка порогового значения\n",
        "    if scores[top_idx] > 0.5:\n",
        "        return documents[top_idx]\n",
        "    else:\n",
        "        return query\n",
        "\n",
        "# Примеры документов\n",
        "documents = [\n",
        "    \"Retrieval-Augmented Generation (RAG) combines retrieval methods with language generation to improve response accuracy.\",\n",
        "    \"Corrective RAG models apply specific techniques to refine and correct generated responses based on context.\",\n",
        "    \"Adaptive RAG is designed to adjust responses dynamically based on query complexity and user intent.\",\n",
        "    \"Recent advances in RAG include models that use self-correction mechanisms to avoid factual errors in generated text.\"\n",
        "]\n",
        "\n",
        "# Запрос для тестирования\n",
        "query = \"What are the latest advancements in RAG, including adaptive and corrective techniques?\"\n",
        "\n",
        "compressed_query = compress_prompt_bert(query, documents)\n",
        "print(\"\\nCompressed Query (BERT):\", compressed_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mY15ZC-jYpJ"
      },
      "source": [
        "### 1.3. Оптимизация запросов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z2rBuQejYpK"
      },
      "source": [
        "**Адаптация к сложности задачи**: Оптимизация позволяет выбрать параметры модели в зависимости от сложности запроса. Например, для длинных и сложных запросов может быть полезно задать более низкий параметр temperature, чтобы получить более последовательный и конкретный ответ.  \n",
        "\n",
        "**Управление длиной ответа**: Настройка параметра max_tokens для ограничения длины генерируемого ответа.  \n",
        "\n",
        "**Контроль уровня детальности**: Например, использование top_p и frequency_penalty, чтобы избежать избыточной детализации или чрезмерных повторений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_6S-fq1jYpK",
        "outputId": "9cbec70e-ed95-4218-f02f-edf8bbe3517b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "# Load environment variables\n",
        "load_dotenv('.env')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8jZAcvRjYpL",
        "outputId": "af7881db-6aba-4e28-d685-0c46b74d92bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized Query Response: \n",
            "\n",
            "1. Real-time monitoring and alerting: Adaptive RAG allows for real-time monitoring and alerting of system performance and health. This helps in identifying and addressing issues before they escalate and impact the overall system.\n",
            "\n",
            "2. Flexibility and scalability: Adaptive RAG can adapt to changes in the system, such as increasing data volume or user traffic, without compromising performance. This makes it suitable for large-scale information systems that need to handle a high volume of data and users.\n",
            "\n",
            "3. Efficient resource utilization: By continuously monitoring and adjusting resources, Adaptive RAG ensures that resources are utilized efficiently. This helps in optimizing system performance and reducing costs.\n",
            "\n",
            "4. Improved system reliability: Adaptive RAG helps in identifying and addressing potential issues before they cause system failures.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def optimized_query(query):\n",
        "    # Настройка параметров на основе длины запроса\n",
        "    if len(query) > 50:\n",
        "        llm = OpenAI(temperature=0.2, max_tokens=150, top_p=0.85)\n",
        "    else:\n",
        "        llm = OpenAI(temperature=0.7, max_tokens=100, top_p=0.95)\n",
        "\n",
        "    # Выполнение запроса\n",
        "    response = llm(query)\n",
        "    return response\n",
        "\n",
        "# Пример использования\n",
        "query = \"What are the primary benefits of using Adaptive RAG in large-scale information systems?\"\n",
        "response = optimized_query(query)\n",
        "print(\"Optimized Query Response:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtYXe7TljYpM"
      },
      "source": [
        "Настройка параметров в зависимости от длины запроса помогает оптимизировать модель для разных типов запросов. Рассмотрим, как каждый параметр работает и почему их значения меняются в зависимости от длины запроса:\n",
        "\n",
        "### Параметры и их роль\n",
        "1. **`temperature`**:\n",
        "   - Этот параметр управляет степенью креативности и разнообразия в ответе.\n",
        "   - Для коротких запросов используется более высокая `temperature` (0.7), что делает ответы более вариативными и подходящими для творческих вопросов.\n",
        "   - Для длинных запросов значение `temperature` понижается (0.2), что уменьшает вариативность и обеспечивает большую точность.\n",
        "\n",
        "2. **`max_tokens`**:\n",
        "   - Это максимальное количество токенов (слов и символов), которое модель может использовать для ответа.\n",
        "   - Длинные запросы обычно требуют более развернутых и точных ответов, поэтому `max_tokens` увеличивается до 150.\n",
        "   - Короткие запросы, наоборот, скорее всего, требуют более кратких ответов, поэтому здесь `max_tokens` ограничено до 100.\n",
        "\n",
        "3. **`top_p`**:\n",
        "   - Этот параметр настраивает фильтрацию наиболее вероятных слов в ответе, что делает текст более связным.\n",
        "   - Для длинных запросов `top_p` снижено до 0.85, чтобы повысить согласованность и уменьшить отклонения от темы.\n",
        "   - Для коротких запросов `top_p` установлено выше (0.95), что позволяет поддерживать разнообразие и детальность в ответе.\n",
        "\n",
        "### Преимущества такой настройки\n",
        "Эти параметры позволяют адаптировать ответы к специфике запроса:\n",
        "- **Для длинных, более сложных запросов**: требуются более точные и развернутые ответы, чего можно достичь снижением `temperature`, увеличением `max_tokens`, и снижением `top_p`.\n",
        "- **Для коротких, общих запросов**: настройка позволяет создавать более живые и разнообразные ответы, ограничивая `max_tokens`, и повышая `temperature` и `top_p`.\n",
        "\n",
        "Эта адаптация помогает контролировать ответы модели, учитывая сложность и потребности конкретного запроса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de2AKncUjYpM"
      },
      "source": [
        "## 2. Продвинутые техники RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83G4q5MZjYpN"
      },
      "source": [
        "### 2.1. Введение в продвинутые техники RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0BL4s5ejYpO"
      },
      "source": [
        "#### 2.1.1. Проблемы базового RAG или почему стандартного RAG недостаточно?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LStlIJryjYpO"
      },
      "source": [
        "Retrieval-Augmented Generation (RAG) — это подход, который объединяет поиск информации и генерацию текста, что позволяет LLM (Large Language Models) получать доступ к информации из внешних источников, таких как базы данных, Википедия и другие документы. Стандартный RAG состоит из двух основных этапов:\n",
        "\n",
        "- **Retrieval (Поиск):** выбор наиболее релевантных документов для запроса.\n",
        "- **Generation (Генерация):** использование этих документов для генерации ответа с помощью модели.\n",
        "\n",
        "Хотя RAG значительно улучшает способность моделей к обработке информации, у этого метода есть несколько ограничений:\n",
        "\n",
        "1. **Зависимость от качества и релевантности извлечённых данных:** стандартный RAG полагается на несколько документов, которые могут не всегда идеально соответствовать запросу. Если подобранные документы недостаточно точные, это напрямую влияет на качество ответа.\n",
        "2. **Ограниченная способность к корректировке неверных данных:** модель RAG генерирует текст на основе извлечённой информации, но при наличии несоответствий или неверной информации в документах, модель не может автоматически исправить эти ошибки.\n",
        "3. **Отсутствие адаптивности к сложности запроса:** стандартный RAG не учитывает специфику запроса. Он одинаково обрабатывает простые и сложные запросы, что может приводить к избыточной или недостаточной информации в ответе.\n",
        "4. **Ресурсоемкость и скорость:** стандартный RAG требует значительных вычислительных ресурсов для работы с большими наборами данных. Извлечение и генерация могут быть медленными и дорогими при обработке сложных или масштабных запросов.\n",
        "\n",
        "Эти ограничения часто становятся особенно заметными в приложениях, где точность и надежность информации играют критическую роль — например, в медицинских системах, юридических консультациях и научных исследованиях.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ5RCE1gjYpP"
      },
      "source": [
        "#### 2.1.2. Какие задачи требуют продвинутых техник RAG?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZhQnTVAjYpP"
      },
      "source": [
        "Продвинутые техники RAG разработаны для того, чтобы решать задачи, которые стандартный RAG не может выполнить на должном уровне. Рассмотрим несколько сценариев, где использование стандартного RAG приводит к неудовлетворительным результатам и требуется внедрение улучшенных методов:\n",
        "\n",
        "1. **Глубокий анализ и корректировка ответов:** В некоторых случаях пользователи хотят не только получить ответ, но и убедиться, что ответ точно соответствует запросу. Если стандартный RAG даёт недостаточно точный результат, требуется механизм корректировки для повышения качества.\n",
        "   \n",
        "2. **Адаптация модели к уровню сложности запроса:** в приложениях, где запросы имеют сильно различающиеся уровни сложности, необходимы методы, которые могут \"подстраиваться\" под каждый конкретный запрос, обеспечивая максимальную релевантность и точность ответа.\n",
        "\n",
        "3. **Устранение противоречий в данных:** данные, извлечённые из разных источников, могут содержать противоречивую информацию. Стандартный RAG не предназначен для устранения таких расхождений, и продвинутые методы, такие как Corrective RAG, могут помочь в решении этой проблемы.\n",
        "\n",
        "4. **Контекстно-зависимые запросы:** в некоторых системах требуется обработка запросов с учётом истории взаимодействий пользователя или предыдущих запросов. Стандартный RAG не сохраняет \"память\" об этих взаимодействиях, поэтому необходимо использовать подходы, позволяющие учитывать прошлую информацию, как в Self-RAG.\n",
        "\n",
        "5. **Универсальность в обработке разных типов данных:** стандартный RAG ограничен текстовыми источниками. Если запросы касаются данных разного формата (например, графов, изображений, аудиофайлов), нужны методы, способные адаптироваться к этим особенностям и работать с разными типами данных.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ePKdRyYjYpQ"
      },
      "source": [
        "#### 2.1.3. Основные направления улучшений и продвинутые техники RAG\n",
        "\n",
        "Существуют несколько подходов к улучшению RAG, каждый из которых решает определённый набор задач. Рассмотрим основные техники и их цели:\n",
        "\n",
        "#### 1. Corrective RAG\n",
        "\n",
        "- **Назначение:** направлен на корректировку ответов, полученных от RAG, для улучшения их точности.\n",
        "- **Принцип работы:** включает дополнительный модуль, который анализирует ответ, сгенерированный моделью, и проверяет его на соответствие исходному запросу. Если ответ содержит неточности, он корректируется, и генерируется новый, уточнённый вариант.\n",
        "- **Применение:** подходит для областей, где важна высокая точность, таких как медицина или право, где ошибка в ответе может привести к негативным последствиям.\n",
        "\n",
        "#### 2. Self-RAG\n",
        "\n",
        "- **Назначение:** Self-RAG позволяет системе сохранять \"память\" о прошлых запросах и ответах, обеспечивая более контекстно-зависимую генерацию ответов.\n",
        "- **Принцип работы:** вместо простого поиска релевантных документов Self-RAG также обращает внимание на предыдущие запросы и ответы, помогая таким образом сохранить связность и непрерывность взаимодействия с пользователем.\n",
        "- **Применение:** идеален для сервисов поддержки клиентов или консультационных систем, где важен учет контекста предыдущих вопросов.\n",
        "\n",
        "#### 3. Adaptive RAG\n",
        "\n",
        "- **Назначение:** автоматическая адаптация параметров генерации ответа в зависимости от сложности и длины запроса.\n",
        "- **Принцип работы:** в Adaptive RAG параметры модели, такие как `temperature`, `max_tokens`, и другие, изменяются динамически в зависимости от структуры запроса. Например, более длинные запросы могут обрабатываться с меньшей температурой для увеличения согласованности ответа, тогда как более простые запросы могут требовать большей вариативности.\n",
        "- **Применение:** эффективен для приложений, где вопросы могут варьироваться от очень простых до сложных, требующих развернутых ответов.\n",
        "\n",
        "#### 4. Prompt Compression and Query Optimization\n",
        "\n",
        "- **Назначение:** упрощение и оптимизация входных данных (запросов), чтобы они содержали только ключевую информацию и занимали меньше ресурсов.\n",
        "- **Принцип работы:** включает предварительную обработку запросов для извлечения наиболее значимых элементов текста, таких как ключевые слова, сущности или важные фразы, что помогает снизить нагрузку на систему.\n",
        "- **Применение:** полезен в ситуациях, где важно экономить вычислительные ресурсы или обрабатывать большие объемы запросов в ограниченные сроки.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFciqcMTjYpQ"
      },
      "source": [
        "### 2.2. Corrective RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDbuxtELjYpR"
      },
      "source": [
        "[Shi-Qi Yan and Jia-Chen Gu and Yun Zhu and Zhen-Hua Ling. Corrective Retrieval Augmented Generation](https://arxiv.org/abs/2401.15884)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc1cPBAKjYpR"
      },
      "source": [
        "#### 2.2.1. Зачем нужен Corrective RAG?\n",
        "\n",
        "Corrective RAG необходим в ситуациях, когда стандартный RAG допускает ошибки при генерации ответа. Эти ошибки могут возникать по нескольким причинам:\n",
        "\n",
        "1. **Неоднозначность запроса:**\n",
        "   - некоторые запросы могут включать сложные или двусмысленные формулировки. Стандартный RAG не всегда способен корректно интерпретировать такие запросы, что приводит к ответам, не полностью отражающим суть вопроса.\n",
        "   \n",
        "2. **Противоречивость данных:**\n",
        "   - при извлечении информации из нескольких источников некоторые данные могут конфликтовать между собой. Например, один документ может содержать одну интерпретацию событий, а другой – противоположную. В таких случаях модель может не выбрать наиболее подходящий источник, что приведет к некорректной генерации.\n",
        "\n",
        "3. **Частичная релевантность:**\n",
        "   - документы, выбранные стандартным RAG, могут частично подходить к запросу, но не полностью, и в результате ответ оказывается неполным или неточным.\n",
        "\n",
        "4. **Роль пользователя в критически важных системах:**\n",
        "   - В ряде сфер (например, здравоохранение, финансы или право) ошибки в ответах могут иметь серьезные последствия. Там, где требуется максимальная точность, Corrective RAG может помочь минимизировать риски.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaJKIKXUjYpR"
      },
      "source": [
        "#### 2.2.2. Принцип работы Corrective RAG\n",
        "\n",
        "Corrective RAG добавляет ещё один слой контроля и корректировки после этапа генерации. Основные компоненты архитектуры Corrective RAG:\n",
        "\n",
        "1. **Модуль извлечения информации (Retrieval):**\n",
        "   - на этом этапе модель извлекает релевантные документы, как и в стандартном RAG, но при этом используется улучшенная фильтрация и предобработка данных для минимизации рисков.\n",
        "   \n",
        "2. **Генерация (Generation):**\n",
        "   - модель формирует начальный ответ на основе извлечённых данных, однако этот ответ ещё не считается окончательным.\n",
        "   \n",
        "3. **Модуль коррекции (Corrective Module):**\n",
        "   - на этом этапе система проверяет сгенерированный ответ на соответствие запросу и наличию ошибок. Этот модуль может использовать дополнительные модели и алгоритмы для анализа текста и выявления противоречий.\n",
        "\n",
        "4. **Повторная генерация или уточнение ответа:**\n",
        "   - если модуль коррекции обнаруживает ошибки или неточности, система может повторить генерацию с уточнёнными параметрами, чтобы добиться лучшего результата."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87q_0l5ijYpS"
      },
      "source": [
        "#### 2.2.3. Методы корректировки в Corrective RAG\n",
        "\n",
        "Существует несколько подходов к корректировке ошибок, которые применяются в Corrective RAG:\n",
        "\n",
        "1. **Сравнение с ключевыми фактами и сущностями:**\n",
        "   - Этот метод использует заранее определенные сущности и ключевые факты, которые модель должна включить в ответ. Модуль коррекции проверяет, упоминаются ли эти элементы в ответе. Если какой-то важный факт отсутствует, модель может перегенерировать ответ, чтобы включить его.\n",
        "   \n",
        "2. **Анализ противоречий:**\n",
        "   - Система может использовать алгоритмы на основе правил или модели, чтобы проверить, не содержит ли ответ противоречий. Например, если ответ ссылается на разные даты для одного и того же события, модель корректирует это расхождение.\n",
        "\n",
        "3. **Контекстная проверка запроса и ответа:**\n",
        "   - Модуль коррекции может оценивать, насколько ответ подходит к контексту запроса. Если ответ кажется слишком общим или не полностью отвечает на вопрос, модель уточняет ответ, добавляя нужные детали.\n",
        "\n",
        "4. **Коррекция с помощью дополнительных примеров:**\n",
        "   - Corrective RAG может использовать базу дополнительных примеров ответов, чтобы сопоставить сгенерированный ответ с эталонными ответами и скорректировать его на основе найденных отклонений.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WLdNxMijYpY"
      },
      "source": [
        "#### 2.2.4. Пример реализации Corrective RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj-CYMB_jYpY"
      },
      "source": [
        "Рассмотрим реализацию Corrective RAG с использованием реального ретривера на основе TF-IDF в LangChain. В данном примере создается база данных документов о достижениях Никола Теслы и применяется коррекция ответа для уточнения результата."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJyTA2S0jYpZ",
        "outputId": "2edb46a9-60e0-436b-b1cb-853f54eda269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Исходный запрос: Расскажите о достижениях Никола Тесла в области электричества.\n",
            "Исправленный запрос: Расскажите о достижениях Никола Тесла в области электричества.. Пожалуйста, укажите: электричество, генератор переменного тока.\n",
            "Ответ после корректировки:  Никола Тесла был известен своими значительными достижениями в области электричества. Он разработал систему переменного тока, которая стала основой для современной электроэнергетики. Также он создал индукционный мотор и генератор переменного тока, что позволило эффективно использовать электрическую энергию для промышленных целей. Тесла также работал над передовыми технологиями передачи энергии и радиосвязи, что существенно повлияло на развитие современных технологий.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.schema import Document\n",
        "\n",
        "# База документов для примера, преобразуем каждый документ в объект Document\n",
        "documents = [\n",
        "    Document(page_content=\"Никола Тесла был инженером и изобретателем, который разработал систему переменного тока.\"),\n",
        "    Document(page_content=\"Его вклад в электротехнику включает создание индукционного мотора и генератора переменного тока.\"),\n",
        "    Document(page_content=\"Тесла также работал над передовыми технологиями передачи энергии и радиосвязи.\"),\n",
        "    Document(page_content=\"Известно, что Тесла разработал первый индукционный двигатель, работающий на переменном токе.\"),\n",
        "    Document(page_content=\"Никола Тесла является одним из наиболее значительных учёных в области электротехники и физики.\"),\n",
        "]\n",
        "\n",
        "# Разделение документов на фрагменты для улучшения поиска\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Создание индекса TF-IDF для поиска по текстам\n",
        "# Создаем новый список документов для TFIDFRetriever\n",
        "retriever = TFIDFRetriever.from_documents(texts)\n",
        "\n",
        "# Настройка модели и QA-цепочки для генерации ответа\n",
        "llm = OpenAI(temperature=0.2)\n",
        "qa_chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n",
        "\n",
        "# Определяем запрос и запускаем генерацию\n",
        "query = \"Расскажите о достижениях Никола Тесла в области электричества.\"\n",
        "print(\"Исходный запрос:\", query)\n",
        "relevant_texts = retriever.get_relevant_documents(query)\n",
        "initial_answer = qa_chain.run(input_documents=relevant_texts, question=query)\n",
        "\n",
        "# Определяем модуль коррекции\n",
        "def corrective_module(answer, query):\n",
        "    # Определяем ключевые сущности для данного запроса\n",
        "    required_entities = [\"Никола Тесла\", \"электричество\", \"достижения\", \"генератор переменного тока\"]\n",
        "\n",
        "    # Проверяем, содержит ли ответ все необходимые сущности\n",
        "    missing_entities = [entity for entity in required_entities if entity not in answer]\n",
        "\n",
        "    if missing_entities:\n",
        "        # Если не хватает сущностей, корректируем запрос\n",
        "        refined_query = f\"{query}. Пожалуйста, укажите: {', '.join(missing_entities)}.\"\n",
        "        print(\"Исправленный запрос:\", refined_query)  # Печать исправленного запроса\n",
        "        # Повторный поиск и генерация ответа\n",
        "        relevant_texts = retriever.get_relevant_documents(refined_query)\n",
        "        corrected_answer = qa_chain.run(input_documents=relevant_texts, question=refined_query)\n",
        "        return corrected_answer\n",
        "    return answer\n",
        "\n",
        "# Применение коррекции\n",
        "final_answer = corrective_module(initial_answer, query)\n",
        "print(\"Ответ после корректировки:\", final_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-XM_SrijYpb"
      },
      "source": [
        "**Пояснение**:\n",
        "\n",
        "1. **База документов**:\n",
        "   - добавляем документы о достижениях Теслы в электротехнике.\n",
        "2. **Text Splitter**:\n",
        "   - этот компонент разбивает большие документы на небольшие фрагменты, чтобы улучшить поиск и сделать извлечение информации более точным.\n",
        "3. **TF-IDF индекс**:\n",
        "   - используется для эффективного извлечения наиболее релевантных документов из базы данных на основе текста запроса.\n",
        "\n",
        "\n",
        "**Пример работы кода**:\n",
        "1. **Первичный запрос**: \"Расскажите о достижениях Никола Тесла в области электричества.\"\n",
        "2. **Первоначальный ответ**: \"Никола Тсела был инженером и изобретателем, который внёс большой вклад в электротехнику.\"\n",
        "3. **Корректировка**: Модуль коррекции добавляет уточнение, и итоговый запрос становится: \"Расскажите о достижениях Никола Тесла в области электричества. Пожалуйста, укажите: генератор переменного тока.\"\n",
        "4. **Корректированный ответ**: \"Никола Тесла разработал генератор переменного тока, который сыграл ключевую роль в развитии современной электротехники.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7gCIlGQjYpb"
      },
      "source": [
        "#### Заключение\n",
        "\n",
        "Corrective RAG представляет собой улучшенную версию стандартного RAG, которая включает механизм обратной связи для корректировки ошибок модели при генерации ответов. Этот подход особенно эффективен в случаях, когда:\n",
        "- **Запросы требуют высокой точности:** Corrective RAG позволяет снизить количество ошибок и неполных ответов, применяя обратную связь и донастройку ретривера для повышения качества извлеченных данных.\n",
        "- **Процесс обучения модели недостаточен:** В ситуациях, когда стандартная модель не справляется с задачей из-за отсутствия специфических знаний, Corrective RAG помогает корректировать и дорабатывать ответы, используя информацию, полученную в ходе предыдущих взаимодействий.\n",
        "- **Сложные вопросы требуют итеративного подхода:** Corrective RAG поддерживает цикличную доработку ответа, что особенно полезно для многослойных вопросов, требующих уточнений и доработок.\n",
        "\n",
        "Corrective RAG идеально подходит для приложений, где важна точность и требуется подробный анализ, таких как юридические консультации, техническая поддержка или обучение. За счет обратной связи и корректировки извлекаемых данных данный метод помогает избежать распространенных ошибок и повышает удовлетворенность пользователей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vASW2gGyjYpc"
      },
      "source": [
        "Реализация Corrective RAG с использованием LangGraph [Corrective RAG (CRAG) using LangGraph](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J81K3E98jYpc"
      },
      "source": [
        "### 2.3. Self-RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHPq9r3YjYpd"
      },
      "source": [
        "#### 2.3.1. Введение в Self-RAG\n",
        "\n",
        "**Self-RAG (Self-Retrieving Augmented Generation)** — это подход, при котором модель сама инициирует дополнительные запросы к системе поиска, чтобы обогатить свой ответ. Self-RAG полезен в случаях, когда исходный ответ неполон, а модель должна сама решить, какие дополнительные сведения нужны для завершения ответа.\n",
        "\n",
        "**Особенности Self-RAG:**\n",
        "- **Самостоятельное уточнение запроса:** Self-RAG позволяет модели анализировать ответ и определять, когда и какие дополнительные данные могут быть полезны.\n",
        "- **Обработка сложных запросов:** Self-RAG применяется для сложных вопросов, которые требуют нескольких этапов поиска и генерации информации.\n",
        "- **Гибкость и адаптивность:** Использование Self-RAG делает модель более гибкой, поскольку она способна решать, что требуется для создания более полного ответа.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCYFv6bmjYpe"
      },
      "source": [
        "#### 2.3.2. Проблемы, решаемые Self-RAG\n",
        "\n",
        "1. **Неполнота информации в одном запросе:**\n",
        "   - иногда начальный запрос не может охватить всю информацию, необходимую для создания полноценного ответа. Self-RAG помогает преодолеть это, выполняя дополнительные запросы по мере необходимости.\n",
        "\n",
        "2. **Автоматизация поиска дополнительных данных:**\n",
        "   - без Self-RAG дополнительные запросы и уточнения обычно задаются вручную. В Self-RAG этот процесс автоматизируется, что упрощает получение необходимых данных.\n",
        "\n",
        "3. **Минимизация ручного вмешательства:**\n",
        "   - self-RAG позволяет модели быть автономной в извлечении информации. Это снижает необходимость в ручном вмешательстве и делает процесс более эффективным.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyZamrJhjYpe"
      },
      "source": [
        "#### 2.3.3. Применение Self-RAG на практике\n",
        "\n",
        "Примером может служить ситуация, когда система отвечает на сложные исторические или научные запросы, которые требуют нескольких уточнений для полноты. Например, запрос о жизни и достижениях какого-либо ученого может требовать дополнительного поиска по разным аспектам: его открытиям, влиянию, значимости для науки и т.д.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUxipJuIjYpf"
      },
      "source": [
        "#### 2.3.4. Пример реализации Self-RAG\n",
        "\n",
        "В LangChain Self-RAG можно реализовать с помощью каскадных запросов, где модель анализирует начальный ответ и формирует новые уточняющие запросы при необходимости. Ниже приведен пример кода, демонстрирующий реализацию Self-RAG.  \n",
        "Пример основан на LangChain и LangGraph, где модель после начального ответа анализирует его на полноту и, если чего-то не хватает, самостоятельно формирует новый запрос.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LrdqoUFjYpf",
        "outputId": "bc7d9f34-b37a-47ec-f362-c36c5345397e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Исходный запрос:  Расскажите о достижениях Никола Тесла в передаче энергии.\n",
            "Первоначальный ответ:  Никола Тесла был известен своими разработками в области электротехники и радиосвязи, включая эксперименты с беспроводной передачей энергии. Он изобрел генератор переменного тока и индукционный мотор, которые стали основой для современных систем электропередачи. Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию, что позволило ему доказать возможность беспроводной передачи энергии на большие расстояния. Его достижения в области передачи энергии имеют огромное значение для современных технологий и по-прежнему используются в настоящее время.\n",
            "Уточненный запрос:  Расскажите о достижениях Никола Тесла в передаче энергии.. Пожалуйста, укажите: передача энергии, радиосвязь, электромагнитные волны.\n",
            "Итоговый ответ с Self-RAG:  Никола Тесла был известен своими разработками в области электротехники и радиосвязи, включая эксперименты с беспроводной передачей энергии. Он изобрел генератор переменного тока и индукционный мотор, которые стали основой для современных систем электропередачи. Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию, что позволило ему доказать возможность беспроводной передачи энергии на большие расстояния. Его достижения в области передачи энергии имеют огромное значение для современных технологий и по-прежнему используются в настоящее время. Дополнительные сведения:  Никола Тесла внес значительный вклад в область передачи энергии, проводя эксперименты с беспроводной передачей энергии. Он также изобрел генератор переменного тока и индукционный мотор, что стало основой для развития электротехники и радиосвязи. Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию, что позволило ему доказать возможность беспроводной передачи энергии на большие расстояния.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Инициализируем базу документов\n",
        "documents = [\n",
        "    \"Никола Тесла был известен своими разработками в области электротехники и радиосвязи.\",\n",
        "    \"Тесла изобрел генератор переменного тока и индукционный мотор.\",\n",
        "    \"Работы Теслы стали важной основой для развития современной электротехники.\",\n",
        "    \"Его вклад включает эксперименты с беспроводной передачей энергии.\",\n",
        "    \"Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию.\"\n",
        "]\n",
        "\n",
        "# Разделяем документы для улучшения поиска\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "\n",
        "# Применяем split_text для каждого документа по отдельности\n",
        "texts = []\n",
        "for doc in documents:\n",
        "    texts.extend(text_splitter.split_text(doc))  # Используем split_text для каждого документа\n",
        "\n",
        "# Создаем список документов для TFIDFRetriever\n",
        "docs = [Document(page_content=text) for text in texts]\n",
        "retriever = TFIDFRetriever.from_documents(docs)\n",
        "\n",
        "# Настройка LLM\n",
        "llm = OpenAI(temperature=0.2)\n",
        "\n",
        "# Создаем цепочку для QA с использованием retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
        "\n",
        "# Определяем запрос\n",
        "query = \"Расскажите о достижениях Никола Тесла в передаче энергии.\"\n",
        "print ('Исходный запрос: ', query)\n",
        "\n",
        "# Запуск начального RAG\n",
        "initial_answer = qa_chain.run(query)\n",
        "print(\"Первоначальный ответ:\", initial_answer)\n",
        "\n",
        "# Функция Self-RAG для самостоятельного уточнения ответа\n",
        "def self_rag(answer, query):\n",
        "    # Проверяем, упомянуты ли ключевые достижения Теслы\n",
        "    required_entities = [\"передача энергии\", \"радиосвязь\", \"электромагнитные волны\"]\n",
        "    missing_entities = [entity for entity in required_entities if entity not in answer]\n",
        "\n",
        "    if missing_entities:\n",
        "        # Формируем новый уточняющий запрос\n",
        "        refined_query = f\"{query}. Пожалуйста, укажите: {', '.join(missing_entities)}.\"\n",
        "        print ('Уточненный запрос: ', refined_query)\n",
        "        additional_info = qa_chain.run(refined_query)\n",
        "        # Объединяем начальный ответ и дополнительную информацию\n",
        "        full_answer = f\"{answer} Дополнительные сведения: {additional_info}\"\n",
        "        return full_answer\n",
        "    return answer\n",
        "\n",
        "# Применяем Self-RAG для уточнения ответа\n",
        "final_answer = self_rag(initial_answer, query)\n",
        "print(\"Итоговый ответ с Self-RAG:\", final_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNLnsH6sjYpg"
      },
      "source": [
        "**Пояснение**:  \n",
        "\n",
        "1. **Инициализация базы документов**:\n",
        "   - создаётся набор текстов, охватывающих основные достижения Никола Теслы.\n",
        "2. **RAG-процесс**:\n",
        "   - изначальный запрос находит информацию о достижениях Теслы. Начальный ответ выводится для анализа.\n",
        "3. **Self-RAG проверка**:\n",
        "   - определяется, содержатся ли ключевые аспекты (такие как передача энергии или электромагнитные волны) в ответе. Если они отсутствуют, генерируется уточняющий запрос.\n",
        "4. **Объединение результатов**:\n",
        "   - если требуется дополнительная информация, она запрашивается и объединяется с начальным ответом, что обеспечивает полноту."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG9DAgWSjYpg"
      },
      "source": [
        "**Пример работы кода**:  \n",
        "\n",
        "**Первичный запрос**: \"Расскажите о достижениях Никола Тесла в передаче энергии.\"  \n",
        "**Первоначальный ответ**: \"Никола Тесла был известен своими разработками в области электротехники.\"  \n",
        "**Уточняющий запрос**: \"Расскажите о достижениях Никола Тесла в передаче энергии. Пожалуйста, укажите: радиосвязь, электромагнитные волны.\"  \n",
        "**Корректированный ответ**: \"Никола Тесла был известен своими разработками в области электротехники. Дополнительные сведения: Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию.\"  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlJAKqJujYph"
      },
      "source": [
        "#### Заключение\n",
        "\n",
        "Self-RAG представляет собой метод, который позволяет модели работать автономно, контролируя процесс поиска и отбора данных для генерации ответа. Этот подход полезен в ситуациях, где:\n",
        "\n",
        "- **Требуется автономность:** Self-RAG дает модели возможность выполнять поиск и выбор информации самостоятельно, минимизируя необходимость внешнего управления и обеспечивая гибкость в обработке запросов.\n",
        "- **Необходимость обработки сложных запросов:** Self-RAG помогает модели разделять и анализировать запросы, адаптируясь к их сложности и при необходимости самостоятельно корректируя выбор ретривера.\n",
        "- **Требования к адаптивности:** Метод Self-RAG позволяет модели анализировать свой собственный ответ и, при необходимости, корректировать его с помощью дополнительного поиска или уточнения информации.\n",
        "\n",
        "Self-RAG подходит для интеллектуальных систем, которым требуется максимальная автономность и точность в ответах, например, для использования в научных исследованиях, аналитике и справочных сервисах. Такой подход позволяет создавать ответы на основе широкого спектра данных и улучшает качество взаимодействия за счет самостоятельной коррекции."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BAX1LmcjYph"
      },
      "source": [
        "### 2.4. Adaptive RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYjzCxJfjYph"
      },
      "source": [
        "#### 2.4.1. Введение в Adaptive RAG\n",
        "\n",
        "**Adaptive RAG (Adaptive Retrieval-Augmented Generation)** — это метод, при котором модель динамически подбирает наиболее подходящий механизм извлечения информации в зависимости от запроса и его сложности. В отличие от стандартных подходов RAG, которые используют один и тот же тип извлечения для всех запросов, Adaptive RAG анализирует запросы и адаптирует стратегию извлечения, что позволяет повысить точность и релевантность ответов.\n",
        "\n",
        "**Основные особенности Adaptive RAG:**\n",
        "- **Гибкость в обработке запросов:** модель может использовать разные подходы к извлечению данных в зависимости от специфики запроса.\n",
        "- **Оптимизация производительности:** адаптация позволяет использовать простые методы для базовых запросов и более сложные методы для многослойных вопросов, снижая нагрузку на систему.\n",
        "- **Многоуровневое извлечение:** модель может комбинировать несколько методов извлечения, чтобы сформировать более информативные ответы на сложные запросы.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQzQ3J5EjYph"
      },
      "source": [
        "#### 2.4.2. Проблемы, решаемые Adaptive RAG\n",
        "\n",
        "1. **Различные уровни сложности запросов:**\n",
        "   - запросы могут варьироваться от простых фактических вопросов до сложных вопросов, требующих многоступенчатого анализа. Adaptive RAG позволяет модели выбирать подходящий уровень извлечения для каждого типа запроса.\n",
        "2. **Избежание избыточного извлечения:**\n",
        "   - стандартные методы RAG могут возвращать больше данных, чем нужно, даже для простых запросов. Adaptive RAG решает эту проблему, снижая объем ненужной информации.\n",
        "3. **Адаптация к типу запроса:**\n",
        "   - adaptive RAG позволяет модели анализировать запрос и выбирать, какой тип информации наиболее важен для ответа (например, обобщенные данные или конкретные факты).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc87D8-EjYpi"
      },
      "source": [
        "#### 2.4.3. Применение Adaptive RAG на практике\n",
        "\n",
        "Adaptive RAG особенно полезен, когда модель обслуживает различные типы пользователей (например, экспертов и начинающих) или обрабатывает многослойные запросы. Примером могут быть научные или аналитические системы, где модель должна корректно оценить запрос и выбрать подходящую стратегию поиска.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUPh2O68jYpj"
      },
      "source": [
        "#### 2.4.5. Реализация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqTGFBnSjYpj"
      },
      "source": [
        "Adaptive RAG может быть реализован через каскадный метод выбора ретривера или же с использованием логики, анализирующей длину и сложность запроса. В примере ниже мы рассмотрим реализацию, где модель сначала проверяет сложность запроса и выбирает подходящий механизм извлечения: простое TF-IDF для базовых запросов и векторный поиск на основе косинусной близости для более сложных запросов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppoe1MmEjYpj",
        "outputId": "e4ca1cb4-a82f-4f28-8e0d-3a3538d909c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Используется TF-IDF для простого запроса.\n",
            "Ответ для простого запроса:  Никола Тесла был известным ученым, который внес значительный вклад в области электротехники и радиосвязи. Он также является одним из самых значимых ученых в истории науки и изучал беспроводную передачу энергии и электромагнитные волны. Его работы стали основой для развития современной электротехники.\n",
            "Используется RAG с векторным индексом для сложного запроса.\n",
            "Ответ для сложного запроса:  Никола Тесла был известен своими разработками в области электротехники и радиосвязи. Он изучал беспроводную передачу энергии и электромагнитные волны, и его работы стали основой для развития современной электротехники. Он создал систему переменного тока, которая стала основой для электрических сетей и применяется по сей день. Также он разработал трансформаторы, которые позволили передавать энергию на большие расстояния без потерь. Он также проводил эксперименты с радиоволнами и создал первую радиоуправляемую модель лодки. Его работы в области электромагнетизма и радиосвязи сыгра\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chains.question_answering.chain import load_qa_chain\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "\n",
        "# Документы для примера\n",
        "documents = [\n",
        "    \"Никола Тесла был известен своими разработками в области электротехники и радиосвязи.\",\n",
        "    \"Он изобрел генератор переменного тока и индукционный мотор.\",\n",
        "    \"Работы Теслы стали основой для развития современной электротехники.\",\n",
        "    \"Тесла изучал беспроводную передачу энергии и электромагнитные волны.\",\n",
        "    \"Никола Тесла является одним из самых значимых ученых в истории науки.\"\n",
        "]\n",
        "\n",
        "# Разделяем документы для улучшения поиска\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "\n",
        "# Применяем split_text для каждого документа по отдельности\n",
        "texts = []\n",
        "for doc in documents:\n",
        "    texts.extend(text_splitter.split_text(doc))\n",
        "\n",
        "# Создаем список документов для TFIDFRetriever\n",
        "docs = [Document(page_content=text) for text in texts]\n",
        "tfidf_retriever = TFIDFRetriever.from_documents(docs)\n",
        "\n",
        "# Настраиваем FAISS векторное хранилище\n",
        "embeddings = OpenAIEmbeddings()\n",
        "faiss_store = FAISS.from_texts(texts, embeddings)\n",
        "faiss_retriever = faiss_store.as_retriever()\n",
        "\n",
        "# Инициализируем модель\n",
        "llm = OpenAI(temperature=0.2)\n",
        "\n",
        "# Создаем цепочку вопросов и ответов\n",
        "llm_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "# Создаем StuffDocumentsChain с правильным использованием llm_chain\n",
        "#combine_documents_chain = StuffDocumentsChain(llm_chain=llm_chain)\n",
        "\n",
        "# Функция для анализа сложности запроса\n",
        "def is_complex_query(query):\n",
        "    return len(query.split()) > 5 or any(word in query.lower() for word in [\"подробно\", \"объясните\", \"детали\"])\n",
        "\n",
        "# Функция Adaptive RAG\n",
        "def adaptive_rag(query):\n",
        "    is_complex = is_complex_query(query)\n",
        "    if is_complex:\n",
        "        print(\"Используется RAG с векторным индексом для сложного запроса.\")\n",
        "        retriever = faiss_retriever\n",
        "    else:\n",
        "        print(\"Используется TF-IDF для простого запроса.\")\n",
        "        retriever = tfidf_retriever\n",
        "\n",
        "    # Создание RAG цепочки с использованием llm и retriever\n",
        "    rag_chain = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
        "    answer = rag_chain.run(query)\n",
        "    return answer\n",
        "\n",
        "# Примеры запросов\n",
        "simple_query = \"Кто такой Никола Тесла?\"\n",
        "complex_query = \"Объясните достижения Никола Теслы в области передачи энергии и электромагнитных волн подробно.\"\n",
        "\n",
        "# Запуск Adaptive RAG для каждого запроса\n",
        "print(\"Ответ для простого запроса:\", adaptive_rag(simple_query))\n",
        "print(\"Ответ для сложного запроса:\", adaptive_rag(complex_query))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx4VYcHrjYpk"
      },
      "source": [
        "**Пояснение к коду**\n",
        "\n",
        "1. **Инициализация базы документов:** Набор текстов о Тесле позволяет создать базу данных для поисковых запросов, предоставляя информацию для обработки запроса на этапе извлечения.\n",
        "2. **TF-IDF и FAISS ретриверы:** Настроены два ретривера:\n",
        "   - `TFIDFRetriever` — для обработки простых запросов.\n",
        "   - `FAISSRetriever` — для работы со сложными запросами, когда необходим более глубокий анализ.\n",
        "3. **Функция `is_complex_query`:** Функция проверяет, является ли запрос сложным, анализируя длину запроса или наличие ключевых слов (например, \"подробно\" или \"объясните\"), которые предполагают более детальный ответ.\n",
        "4. **Adaptive RAG логика:** В зависимости от результата `is_complex_query`, выбирается соответствующий ретривер. Если запрос признан сложным, применяется FAISS, в противном случае — TF-IDF.\n",
        "5. **Запросы и ответы:** На простые запросы система отвечает с помощью TF-IDF, а на сложные — с помощью векторного поиска (FAISS), что оптимизирует процесс поиска и повышает релевантность ответов.\n",
        "\n",
        "**Пример работы кода**\n",
        "\n",
        "1. **Простой запрос:** `\"Кто такой Никола Тесла?\"`\n",
        "   - **Выбранный ретривер:** TF-IDF\n",
        "   - **Ответ:** `\"Никола Тесла был известен своими разработками в области электротехники и радиосвязи.\"`\n",
        "   \n",
        "2. **Сложный запрос:** `\"Объясните достижения Никола Теслы в области передачи энергии и электромагнитных волн подробно.\"`\n",
        "   - **Выбранный ретривер:** FAISS\n",
        "   - **Ответ:** `\"Тесла изучал беспроводную передачу энергии и электромагнитные волны. Его эксперименты в этой области стали важной основой для развития науки.\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUPlyoxWjYpl"
      },
      "source": [
        "#### Заключение\n",
        "\n",
        "Adaptive RAG позволяет модели динамически адаптироваться к типу запроса, что повышает качество и релевантность ответов, а также снижает нагрузку на систему. Это особенно полезно в ситуациях, когда:\n",
        "- **Запросы различаются по сложности:** Adaptive RAG позволяет подбирать стратегию поиска для каждого запроса индивидуально.\n",
        "- **Производительность критична:** Использование более простых методов для простых запросов и мощных методов для сложных снижает общую нагрузку.\n",
        "- **Требуется высокая точность:** Adaptive RAG позволяет более точно отвечать на сложные вопросы, адаптируя глубину ответа под запрос.\n",
        "\n",
        "Adaptive RAG идеально подходит для профессиональных, научных и аналитических приложений, требующих высокого уровня точности и гибкости при обработке запросов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jkaS7PMjYpl"
      },
      "source": [
        "### 2.5. Сравнение различных подходов RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iBa8Vj_jYpm"
      },
      "source": [
        "1. **Simple RAG**:\n",
        "   - Используется стандартный подход с RetrievalQA и векторным хранилищем.\n",
        "2. **Corrective RAG**:\n",
        "   - Введен специальный шаблон для исправления ошибок в ответах.\n",
        "3. **Self-RAG**:\n",
        "   - Используется самокоррекция в ответах, дополненная уточняющими деталями.\n",
        "4. **Adaptive RAG**:\n",
        "   - Применяется подход с анализом сложности запроса (с использованием TF-IDF для простых запросов и FAISS для сложных)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzooogTAjYpm",
        "outputId": "834ee0bf-8870-41ae-c5cc-760ec865bd00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Используется RAG с векторным индексом для сложного запроса.\n",
            "\n",
            "\n",
            "Simple RAG ответ:\n",
            " Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния. Тесла провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии, что продемонстрировало огромный потенциал высокочастотных электрических волн. Он также был пионером в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности. Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций.\n",
            "--------------------------------------------------\n",
            "\n",
            "Corrective RAG ответ:\n",
            " Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния. Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций. В 1899 году Тесла провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии, что продемонстрировало огромный потенциал высокочастотных электрических волн. Тесла был одним из пионеров в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности.\n",
            "--------------------------------------------------\n",
            "\n",
            "Self-RAG ответ:\n",
            " Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он родился в 1856 году в Хорватии, а в 1884 году переехал в США, где и начал свою научную карьеру. Тесла был одним из пионеров в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния, а также провел знаменитые эксперименты в Колорадо-Спрингс в 1899 году, где ему удалось создать искусственные молнии и продемонстрировать огромный потенциал высокочастотных электрических волн. Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций.\n",
            "--------------------------------------------------\n",
            "\n",
            "Adaptive RAG ответ:\n",
            " Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния. Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций. В 1899 году Тесла провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии, что продемонстрировало огромный потенциал высокочастотных электрических волн. Он также был одним из пионеров в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности. Тесла был человеком, который всегда стремился к новым открытиям и идеям, и его вклад в науку и технологии до сих пор остается значительным.\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains.question_answering.chain import load_qa_chain\n",
        "\n",
        "# Подготовка LLM и эмбеддингов\n",
        "llm = OpenAI(temperature=0.2, max_tokens=512)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Примеры документов о Николе Тесле\n",
        "documents = [\n",
        "    \"Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния.\",\n",
        "    \"В 1891 году Тесла продемонстрировал передачу энергии без проводов, что стало важным шагом в развитии беспроводных технологий.\",\n",
        "    \"Исследования Теслы в области высокочастотного переменного тока привели к разработке систем, способных передавать электроэнергию без использования проводов на значительные расстояния.\",\n",
        "    \"Работы Теслы легли в основу многих современных технологий, включая радиосвязь и системы передачи данных.\",\n",
        "    \"Тесла также экспериментировал с беспроводной передачей информации и энергии, создав прототипы, которые значительно опережали время. Его работы по радиоволнам стали основой для дальнейших достижений в области телекоммуникаций.\",\n",
        "    \"В 1899 году Тесла провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии, что продемонстрировало огромный потенциал высокочастотных электрических волн.\",\n",
        "    \"Тесла был одним из пионеров в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности.\",\n",
        "    \"В 1917 году Тесла предложил концепцию мирового беспроводного радио и связи, которая предвосхитила современную мобильную коммуникацию.\",\n",
        "    \"Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций.\"\n",
        "]\n",
        "\n",
        "# Разделение текста на куски для обеспечения правильного поиска\n",
        "splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "\n",
        "# Применяем split_text для каждого документа по отдельности\n",
        "texts = []\n",
        "for doc in documents:\n",
        "    texts.extend(splitter.split_text(doc))\n",
        "\n",
        "# Создаем список документов для TFIDFRetriever\n",
        "docs = [Document(page_content=text) for text in texts]\n",
        "\n",
        "\n",
        "\n",
        "# Подготовка векторного хранилища для VectorstoreRetriever\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "vectorstore_retriever = vectorstore.as_retriever()\n",
        "\n",
        "# TF-IDF retriever\n",
        "tfidf_retriever = TFIDFRetriever.from_texts([doc.page_content for doc in docs])\n",
        "\n",
        "# Шаблон для Corrective RAG\n",
        "corrective_template = \"\"\"Ответьте на запрос, используя следующие документы:\n",
        "{context}\n",
        "Запрос: {query}\n",
        "Коррекция: если в ответе есть ошибка или неверная информация, исправьте ее.\n",
        "\n",
        "Ответ:\"\"\"\n",
        "corrective_prompt = PromptTemplate(input_variables=[\"context\", \"query\"], template=corrective_template)\n",
        "\n",
        "# Шаблон для Self-RAG\n",
        "self_rag_template = \"\"\"Ответьте на запрос, используя следующие документы:\n",
        "{context}\n",
        "Запрос: {query}\n",
        "Используйте самокоррекцию, чтобы избежать ошибок в ответе и добавьте уточняющие детали.\n",
        "\n",
        "Ответ:\"\"\"\n",
        "self_rag_prompt = PromptTemplate(input_variables=[\"context\", \"query\"], template=self_rag_template)\n",
        "\n",
        "# Подготовка цепочек для каждого подхода\n",
        "simple_rag = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore_retriever)\n",
        "corrective_rag = LLMChain(llm=llm, prompt=corrective_prompt)\n",
        "self_rag = LLMChain(llm=llm, prompt=self_rag_prompt)\n",
        "\n",
        "# Настройка Adaptive RAG\n",
        "# Инициализация FAISS и настройки цепочек\n",
        "faiss_store = FAISS.from_texts([doc.page_content for doc in docs], embeddings)\n",
        "faiss_retriever = faiss_store.as_retriever()\n",
        "\n",
        "# Функция для анализа сложности запроса\n",
        "def is_complex_query(query):\n",
        "    return len(query.split()) > 5 or any(word in query.lower() for word in [\"подробно\", \"объясните\", \"детали\"])\n",
        "\n",
        "# Функция Adaptive RAG\n",
        "def adaptive_rag(query):\n",
        "    is_complex = is_complex_query(query)\n",
        "    if is_complex:\n",
        "        print(\"Используется RAG с векторным индексом для сложного запроса.\\n\\n\")\n",
        "        retriever = faiss_retriever\n",
        "    else:\n",
        "        print(\"Используется TF-IDF для простого запроса.\\n\\n\")\n",
        "        retriever = tfidf_retriever\n",
        "\n",
        "    # Создание RAG цепочки с использованием llm и retriever\n",
        "    rag_chain = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
        "    answer = rag_chain.run(query)\n",
        "    return answer\n",
        "\n",
        "# Функция для выполнения запроса с каждым подходом\n",
        "def compare_rag_approaches(query):\n",
        "    responses = {}\n",
        "\n",
        "    # Simple RAG\n",
        "    responses['Simple RAG'] = simple_rag.run(query)\n",
        "\n",
        "    # Corrective RAG\n",
        "    context = vectorstore_retriever.get_relevant_documents(query)\n",
        "    responses['Corrective RAG'] = corrective_rag.run({\"context\": context, \"query\": query})\n",
        "\n",
        "    # Self-RAG\n",
        "    responses['Self-RAG'] = self_rag.run({\"context\": context, \"query\": query})\n",
        "\n",
        "    # Adaptive RAG\n",
        "    responses['Adaptive RAG'] = adaptive_rag(query)\n",
        "\n",
        "    return responses\n",
        "\n",
        "# Пример использования\n",
        "#query = \"Объясните достижения Никола Теслы в области передачи энергии и электромагнитных волн подробно.\"\n",
        "query = \"Расскажи подробно про Никола Тесла.\"\n",
        "results = compare_rag_approaches(query)\n",
        "\n",
        "# Вывод результатов для сравнения\n",
        "for approach, response in results.items():\n",
        "    print(f\"{approach} ответ:\\n{response}\\n{'-'*50}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}